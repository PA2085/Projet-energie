import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import statsmodels.api as sm
import sklearn.metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from PIL import Image
import joblib

df=pd.read_csv("eco2mix-regional-cons-def.csv",sep=";")

st.sidebar.title("Projet √©nergie")

pages=["Pr√©sentation","Exploration et pr√©-processing","Enrichissement de la base","Visualisations","Machine learning ","Conclusion"]

page=st.sidebar.radio("Menu",pages)

if page == pages[0] :
    st.write("### Objectif")
    st.write("L'objectif du projet est de constater le phasage entre la consommation et la production √©nerg√©tique au niveau national et au niveau r√©gional (risque de black out notamment).")
    st.write("### Dataset")
    image=Image.open("Carte_ODRE.jpg")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.image(image, use_column_width=True)
    st.write("Le jeu de donn√©es est issu de la source de donn√©es de l'ODRE (Open Data R√©seaux √ânergies) avec un acc√®s √† toutes les informations de consommation et de production d'√©lectricit√© par fili√®re par jour (toutes les 1/2 heure) et par r√©gion depuis 2013.")
    st.write("Les donn√©es proviennent d‚Äôune application √©CO2mix et sont mises √† disposition sous data.gouv.fr ou sur odre.opendatasoft.com .")
    st.write('Extrait du data set : 10 premi√®res lignes')
    st.dataframe(df.head(10))
    st.write("Contenu du jeu de donn√©es :")
    st.write("‚óè  la consommation d'√©lectricit√©")
    st.write("‚óè  la production d'√©lectricit√© par fili√®re")
    st.write("‚óè  la consommation des pompes dans les Stations de Transfert d'Energie par Pompage (STEP)")
    st.write("‚óè  le solde des √©changes avec les r√©gions limitrophes")
    st.write("‚óè  TCO : le Taux de COuverture (TCO) de chaque fili√®re de production, soit la part d'une fili√®re dans la production totale")
    st.write("‚óè  TCH : le Taux de CHarge (TCH) ou facteur de charge (FC) d'une fili√®re repr√©sente son volume de production par rapport √† la capacit√© de production install√©e et en service de cette fili√®re.")
    
if page == pages[4] :
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["üéØ  Valeur cible", "üßπ Preprocessing","üìä Mod√©lisation", "‚öôÔ∏è Optimisation","üìà Visualisations","‚è≥ Prophet"])

    with tab1:
          st.header("Choix de la valeur cible")
          st.write("L‚Äôun des objectifs de cette mod√©lisation est de pr√©dire le risque de black-out √©lectrique en France, c‚Äôest-√†-dire une situation o√π la demande en √©lectricit√© ne pourrait plus √™tre satisfaite par l‚Äôoffre, provoquant des coupures g√©n√©ralis√©es.")
          st.write("Dans cette optique, nous avions choisi initialement comme valeur cible le solde √©lectrique, d√©fini comme : ")
          st.write("Solde √©lectrique = Consommation d‚Äô√©lectricit√© ‚Äì Production totale (toutes fili√®res confondues)")
          st.write("Limites :")
          st.write("- Donn√©es incompl√®tes sur les capacit√©s de production maximales")
          st.write("- R√©sultats non concluants des mod√®les pr√©dictifs test√©s ")
          st.write("Valeur cible retenue :")
          st.write("- Pr√©diction de la consommation √©lectrique par jour")

    with tab2 :
        st.write("### Principales √©tapes de pr√©paration du dataset")
        st.write("1. Encodage des variables non num√©riques :")
        st.write("- Transformation des valeurs temporelles avec encodage cyclique pour le mois et le jour ")
        st.write("- Transformation des colonnes en valeur bool√©enne (p√©riode de chauffe)")
        st.write("2. S√©paration des donn√©es : La variable cible a √©t√© s√©par√©e des variables explicatives.")
        st.write("3. S√©paration Train/Test : Le dataset a √©t√© divis√© en un ensemble d‚Äôentra√Ænement (80 %) et un ensemble de test (20 %).")
        st.write("4. Gestion des valeurs manquantes : Les valeurs manquantes ont √©t√© imput√©es avec la moyenne des colonnes, √† l‚Äôaide de SimpleImputer.")
        st.write("5. Standardisation des variables : Les valeurs num√©riques ont √©t√© standardis√©es pour garantir une √©chelle comparable entre les variables avec StandardScaler.")
    
    with tab3:
          st.write("### Choix des mod√®les entra√Æn√©s :")
          st.write("Pour la mod√©lisation, nous avons retenu 4 mod√®les diff√©rents :")
          st.write("- la r√©gression lin√©aire : approche simple, interpr√©table et rapide √† mettre en oeuvre")
          st.write("- un arbre de d√©cision : facilement interpr√©table mais pr√©sente un risque de surapprentissage")
          st.write("- une for√™t al√©atoire : approche optimis√©e de l'arbre de d√©cision")
          st.write("- le mod√®le XG boost : mod√®le qui permet de r√©duire le risque d'apprentissage")
          
          df_ML=pd.read_csv("df_conso_ML.csv",sep=",")
          df_ML_rest=df_ML.drop(['mois','jour','R√©gion','region'],axis=1)
          x=df_ML_rest.drop('consommation',axis=1)
          y=df_ML_rest['consommation']
          X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.2, random_state=42)
          imputer=SimpleImputer (strategy='mean')
          col=['TMin','TMax','TMoy']
          X_train[col]=imputer.fit_transform(X_train[col])
          X_test[col]=imputer.transform(X_test[col])
          X_train['periode_de_chauffe']=X_train['periode_de_chauffe'].astype('int')
          X_test['periode_de_chauffe']=X_test['periode_de_chauffe'].astype('int')
          datetime_col_train = X_train[['date']]
          datetime_col_test = X_test[['date']]
          X_train_numeric = X_train.drop(columns=['date'])
          X_test_numeric = X_test.drop(columns=['date'])
          scaler=StandardScaler()
          scaler.fit(X_train_numeric)
          X_train_scaled=scaler.transform (X_train_numeric)
          X_test_scaled=scaler.transform(X_test_numeric)
          
          
          st.write("### Extrait du dataset utilis√© pour la mod√©lisation")
          if st.checkbox("Afficher le dataset utilis√© pour le ML") :
                   st.dataframe(df_ML_rest.head())
        
          st.write("### R√©sultats de chaque mod√®le :")
          lr=joblib.load("model_lr.pkl")
          dtr=joblib.load("model_dtr.pkl")
          rfr=joblib.load("model_rfr.pkl")
          xgb=joblib.load("model_xgb.pkl")

          y_pred_lr=lr.predict(X_test_scaled)
          y_pred_dtr=dtr.predict(X_test_scaled)
          y_pred_rfr=rfr.predict(X_test_scaled)
          y_pred_xgb=xgb.predict(X_test_scaled)
          
          modele_choisi=st.selectbox(label='Choix du mod√®le', options=['Linear Regression','Decision Tree','Random Forest','XG Boost'])
          st.write("R√©sultats des m√©triques (jeu de test) : ")
          
          def train_model_r2(modele_choisi) :
            if modele_choisi == 'Linear Regression' :
                y_pred=y_pred_lr
            elif modele_choisi == 'Decision Tree' :
                y_pred=y_pred_dtr
            elif modele_choisi == 'Random Forest' :
                y_pred=y_pred_rfr
            elif modele_choisi == 'XG Boost' :
                y_pred=y_pred_xgb
            r2=r2_score(y_test, y_pred)
            mae=mean_absolute_error(y_test, y_pred)
            return r2
          st.write("Score : ",train_model_r2(modele_choisi))
    
          def train_model_mae(modele_choisi) :
            if modele_choisi == 'Linear Regression' :
                y_pred=y_pred_lr
            elif modele_choisi == 'Decision Tree' :
                y_pred=y_pred_dtr
            elif modele_choisi == 'Random Forest' :
                y_pred=y_pred_rfr
            elif modele_choisi == 'XG Boost' :
                y_pred=y_pred_xgb
            mae=mean_absolute_error(y_test, y_pred)
            return mae
          st.write("MAE : ",train_model_mae(modele_choisi))

          def train_model_mse(modele_choisi) :
            if modele_choisi == 'Linear Regression' :
                y_pred=y_pred_lr
            elif modele_choisi == 'Decision Tree' :
                y_pred=y_pred_dtr
            elif modele_choisi == 'Random Forest' :
                y_pred=y_pred_rfr
            elif modele_choisi == 'XG Boost' :
                y_pred=y_pred_xgb
            mse=mean_squared_error(y_test, y_pred)
            return mse
          st.write("MSE : ",train_model_mse(modele_choisi))

          def train_model_rmse(modele_choisi) :
            if modele_choisi == 'Linear Regression' :
                y_pred=y_pred_lr
            elif modele_choisi == 'Decision Tree' :
                y_pred=y_pred_dtr
            elif modele_choisi == 'Random Forest' :
                y_pred=y_pred_rfr
            elif modele_choisi == 'XG Boost' :
                y_pred=y_pred_xgb
            rmse= mean_squared_error(y_test, y_pred)**0.5
            return rmse
          st.write("RMSE : ",train_model_rmse(modele_choisi))
          
          def comment_model(modele_choisi) :
            if modele_choisi == 'Linear Regression' :
                comment=st.markdown(" Le mod√®le **Linear regression** montre des performances correctes, mais limit√©es. Il capture les tendances globales mais a du mal √† mod√©liser les variations fines de la consommation.")
            elif modele_choisi == 'Decision Tree' :
                comment=st.markdown("Le mod√®le **Decision Tree** pr√©sente un surapprentissage √©vident. L‚Äôerreur est nulle sur le jeu d'entra√Ænement (score train = 1) mais nettement plus √©lev√©e sur le jeu de test, ce qui r√©v√®le une mauvaise g√©n√©ralisation.")
            elif modele_choisi == 'Random Forest' :
                comment=st.markdown("Le mod√®le **Random Forest** am√©liore nettement la performance par rapport √† l‚Äôarbre unique, avec une bonne capacit√© de g√©n√©ralisation. Il r√©duit consid√©rablement les erreurs de test tout en gardant un excellent score R¬≤.")
            elif modele_choisi == 'XG Boost' :
                comment=st.markdown("Le mod√®le **XG Boost** surpasse l‚Äôensemble des autres mod√®les sur toutes les m√©triques du jeu de test. Il pr√©sente les meilleures performances en termes de pr√©cision et de g√©n√©ralisation.")
            return comment
          comment_model(modele_choisi)
          
          
          

    with tab4:
        st.markdown("*Les mod√®les RandomForest et XGBoost affichent d√©j√† d‚Äôexcellentes performances (plus de 97‚ÄØ%). Cela soul√®ve la question de l‚Äôutilit√© d‚Äôune optimisation suppl√©mentaire et du risque possible de surapprentissage. Dans cette perspective, nous avons consid√©r√© que l‚Äôoptimisation des hyperparam√®tres ne viserait pas uniquement √† am√©liorer la pr√©cision brute du mod√®le, mais √©galement √† renforcer sa stabilit√© et √† optimiser le risque de surapprentissage.*")
        st.write("### Choix des mod√®les √† optimiser")
        st.write("Parmi les mod√®les √©valu√©s, XGBoost et Random Forest ont d‚Äôexcellentes performances. Les performances de ces 2 mod√®les sont tr√®s proches. Sur les visualisations ci-dessous qui comparent la pr√©dictions au r√©el, on constate que le mod√®le XG Boost est l√©g√®rement plus centr√© sur la droite rouge qui repr√©sente l‚Äô√©galit√© parfaite entre les valeurs pr√©dites et les observations r√©elles :")
        st.image("graph_pred_vs_reel.jpg")
        st.write("### Optimisation des mod√®les avec Grid Search")
        st.write("##### - Random Forest :")
        st.write("L‚Äôajustement du nombre d‚Äôarbres (n_estimators) et la profondeur (max_depth) permet d‚Äô√©viter le sur-apprentissage. La s√©lection automatique des features (max_features) am√©liore la diversit√© des arbres, donc la pr√©cision.")
        if st.checkbox("Afficher le code",key="code_rfr") :
            code_1="""
            param_grid_rfr = {
            'n_estimators': [100, 200],  # Nombre d'arbres
            'max_depth': [None, 10, 20], # Profondeur des arbres
            'min_samples_split': [2, 5], # Nombre minimal d'√©chantillons
            'max_features': ['sqrt', 'log2', None]  # nombre de variables utilis√©es
            }
            
            grid_search_rfr = GridSearchCV(rfr, param_grid_rfr, cv=5, 
            scoring='neg_root_mean_squared_error', n_jobs=-1) # Initialiser GridSearchCV

            grid_search_rfr.fit(X_train_numeric, y_train) # Entra√Æner GridSearch

            print("Meilleurs param√®tres :", grid_search_rfr.best_params_)

            """
            st.code(code_1, language="python")
        st.markdown("**Les meilleurs param√®tres pour le mod√®le Random Forest sont les suivants :**")
        st.markdown("max_depth: **None**<br>max_features: **sqrt**<br>min_samples_split: **2**<br>n_estimators : **200**", unsafe_allow_html=True)
        
        st.write("##### - XG Boost :")
        st.write("A l‚Äôimage de Random Forest, l‚Äôajustement du nombre d‚Äôarbres (n_estimators) et la profondeur (max_depth) a pour but d‚Äô√©viter le sur-apprentissage. De plus, subsample et colsample_bytree r√©duisent la variance pour √©viter le sur-apprentissage. Enfin, le learning rate a quant √† lui un impact sur la dur√©e de l'entra√Ænement des donn√©es. ")
        if st.checkbox("Afficher le code",key="code_xgb") :
            code_2="""
            param_grid_xgb = {
                'n_estimators': [100, 200, 500],   # Nombre d'arbres
                'learning_rate': [0.01, 0.05, 0.1], # Taux d'apprentissage
                'max_depth': [3, 6, 9],          # Profondeur des arbres
                'subsample': [0.6,0.8, 1],        # Pourcentage de donn√©es utilis√©es
                'colsample_bytree': [0.6,0.8, 1]  # Pourcentage de variables utilis√©es
            }

            grid_search_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5,
            scoring='neg_root_mean_squared_error', n_jobs=-1) # Initialiser GridSearchCV

            grid_search_xgb.fit(X_train_numeric, y_train) # Entra√Æner GridSearch

            print("Meilleurs param√®tres :", grid_search_xgb.best_params_)
            """
            st.code(code_2, language="python")
        
        st.markdown("**Les meilleurs param√®tres pour le mod√®le XG Boost sont les suivants :**")
        st.markdown("colsample_bytree : **0.8**<br>learning_rate : **0.1**<br>max_depth :**9**<br>n_estimators : **500**<br>subsample : **1**", unsafe_allow_html=True)

        st.write("### Comparaison des r√©sultats")
        st.image("tab_recap_metr.jpg")
        st.write("On constate que l‚Äôoptimisation des hyperparam√®tres a permis de r√©duire les m√©triques MAE, MSE et RMSE, ainsi qu‚Äôune l√©g√®re augmentation du score R¬≤.")
        st.write("L‚Äôam√©lioration des m√©triques est plus marqu√©e pour XGBoost que Random Forest.")

    with tab6:
        st.markdown("*La pr√©diction de la consommation d‚Äô√©lectricit√© en France s‚Äôinscrit dans un cadre typique de mod√©lisation de s√©ries temporelles. Dans ce contexte, nous avons choisi d‚Äôexp√©rimenter Prophet, un mod√®le d√©velopp√© par Facebook sp√©cifiquement con√ßu pour la pr√©vision de s√©ries chronologiques.*")
        st.write("##### Mod√©lisation")
        st.write("Prophet pr√©sente l‚Äôavantage d‚Äôune mise en ≈ìuvre rapide et simple, ne n√©cessitant que deux variables principales : la date (ds) et la valeur cible (y).")
        st.write("Nous avons param√©tr√© le mod√®le avec comme valeur cible la consommation et une s√©paration du jeu d'entra√Ænement et de test de 80%/20%.")
        
        if st.checkbox("Afficher le code",key="code_prophet") :
            code_3="""
            from prophet import Prophet

            # DF prophet
            df_prophet=df_conso_tot.groupby('date').agg(
                {'consommation':'sum'}).reset_index()
            df_prophet=df_prophet.rename(columns={'date': 'ds','consommation':'y'})

            # S√©paration jeu d'enrainement et de test
            split_index = int(len(df_prophet) * 0.8)
            train_prophet = df_prophet.iloc[:split_index]
            test_prophet = df_prophet.iloc[split_index:]

            # Entrainement
            model = Prophet()
            model.fit(train_prophet)

            # Pr√©dictions
            future = model.make_future_dataframe(periods=len(test_prophet), freq='D')
            forecast = model.predict(future)

            # Mod√©lisation
            fig = model.plot(forecast)
            plt.show()

            # Composantes de la s√©rie temporelle
            model.plot_components(forecast);
            """
            st.code(code_3, language="python")

        st.write("Il permet de mod√©liser automatiquement les tendances, les saisonnalit√©s multiples et les effets de jours f√©ri√©s. Voici les tendances identifi√©es sur notre s√©rie : ")
     
        trend=st.selectbox(label='Choix de la tendance', options=["par ann√©e","sur la semaine","sur l'ann√©e"])
        def trend_show(trend) :
            if trend== "par ann√©e" :
                img=st.image("prophet_trend.jpg")
            elif trend== "sur la semaine" :
                img=st.image("prophet_weekly.jpg")
            elif trend == "sur l'ann√©e" :
                img=st.image("prophet_yearly.jpg")
            return img
        trend_show(trend)
    




             


